{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:\\College\\Projects\\Signature Verification using Siamese Neural Network\")\n",
    "from Models.models import Model_BN\n",
    "from utils import ContrastiveLoss, transform, SiameseDataset, TrainLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_BN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Siamese CNN model with Batch Normalization.\n",
    "\n",
    "    This model consists of three shared convolutional layers with Batch Normalization\n",
    "    followed by Fully Connected layers for feature extraction. The architecture is designed\n",
    "    to take two input images (x_genuine and x_test) and process them through the same\n",
    "    set of convolutional layers before extracting feature vectors.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Shape:\n",
    "        - Input:\n",
    "            - x_genuine (torch.Tensor): A 4D tensor representing a batch of genuine images\n",
    "              with shape (batch_size, channels, height, width).\n",
    "            - x_test (torch.Tensor): A 4D tensor representing a batch of test images\n",
    "              with shape (batch_size, channels, height, width).\n",
    "\n",
    "        - Output:\n",
    "            - y_genuine (torch.Tensor): A 2D tensor representing the feature vectors of the\n",
    "              genuine images with shape (batch_size, 128).\n",
    "            - y_test (torch.Tensor): A 2D tensor representing the feature vectors of the\n",
    "              test images with shape (batch_size, 128).\n",
    "\n",
    "    Model Architecture:\n",
    "        --------------------------------------------------------------------\n",
    "        Layer (type)            Output Shape                        Param #\n",
    "        ====================================================================\n",
    "        Conv2d-1                [batch_size, 96, 210, 145]          34,944\n",
    "        SELU-2                  [batch_size, 96, 210, 145]               0\n",
    "        BatchNorm2d-3           [batch_size, 96, 210, 145]             192\n",
    "        SELU-4                  [batch_size, 96, 210, 145]               0\n",
    "        MaxPool2d-5             [batch_size, 96, 104, 72]                0\n",
    "        Conv2d-6                [batch_size, 256, 104, 72]         614,656\n",
    "        SELU-7                  [batch_size, 256, 104, 72]               0\n",
    "        BatchNorm2d-8           [batch_size, 256, 104, 72]             512\n",
    "        SELU-9                  [batch_size, 256, 104, 72]               0\n",
    "        MaxPool2d-10            [batch_size, 256, 51, 35]                0\n",
    "        Dropout2d-11            [batch_size, 256, 51, 35]                0\n",
    "        Conv2d-12               [batch_size, 384, 51, 35]          885,120\n",
    "        SELU-13                 [batch_size, 384, 51, 35]                0\n",
    "        Conv2d-14               [batch_size, 256, 51, 35]          884,992\n",
    "        SELU-15                 [batch_size, 256, 51, 35]                0\n",
    "        MaxPool2d-16            [batch_size, 256, 25, 17]                0\n",
    "        Dropout2d-17            [batch_size, 256, 25, 17]                0\n",
    "        Flatten-18              [batch_size, 108800]                     0\n",
    "        Linear-19               [batch_size, 1024]             111,412,224\n",
    "        SELU-20                 [batch_size, 1024]                       0\n",
    "        Dropout1d-21            [batch_size, 1024]                       0\n",
    "        Linear-22               [batch_size, 128]                  131,200\n",
    "        ===================================================================\n",
    "        Total params: 113,963,840\n",
    "        Trainable params: 113,963,840\n",
    "        Non-trainable params: 0\n",
    "        -------------------------------------------------------------------\n",
    "\n",
    "    Note:\n",
    "        SELU activation is used after each convolutional layer, and Dropout is applied\n",
    "        for regularization to prevent overfitting.\n",
    "\n",
    "    Example:\n",
    "        # Create an instance of the Model_BN\n",
    "        model = Model_BN()\n",
    "\n",
    "        # Assuming you have loaded the genuine and test images as tensors\n",
    "        genuine_images = ...  # Tensor of genuine images\n",
    "        test_images = ...  # Tensor of test images\n",
    "\n",
    "        # Pass the images through the model\n",
    "        feature_vectors_genuine, feature_vectors_test = model(genuine_images, test_images)\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model_branch = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.BatchNorm2d(num_features=96),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.BatchNorm2d(num_features=256),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Dropout2d(p=0.3),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Dropout2d(p=0.3),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=24576, out_features=1024),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout1d(p=0.5),\n",
    "            torch.nn.Linear(in_features=1024, out_features=128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_genuine, x_test):\n",
    "        \"\"\"\n",
    "        Forward pass of the Siamese CNN model.\n",
    "\n",
    "        Args:\n",
    "            x_genuine (torch.Tensor): A batch of genuine images with shape (batch_size, channels, height, width).\n",
    "            x_test (torch.Tensor): A batch of test images with shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor representing the feature vectors of the genuine images with shape (batch_size, 128).\n",
    "            torch.Tensor: A tensor representing the feature vectors of the test images with shape (batch_size, 128).\n",
    "        \"\"\"\n",
    "        y_genuine = self.model_branch(x_genuine)\n",
    "        y_test = self.model_branch(x_test)\n",
    "        return torch.nn.functional.pairwise_distance(y_genuine, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 145, 210]          11,712\n",
      "              SELU-2         [-1, 96, 145, 210]               0\n",
      "       BatchNorm2d-3         [-1, 96, 145, 210]             192\n",
      "              SELU-4         [-1, 96, 145, 210]               0\n",
      "         MaxPool2d-5          [-1, 96, 72, 104]               0\n",
      "            Conv2d-6         [-1, 256, 72, 104]         614,656\n",
      "              SELU-7         [-1, 256, 72, 104]               0\n",
      "       BatchNorm2d-8         [-1, 256, 72, 104]             512\n",
      "              SELU-9         [-1, 256, 72, 104]               0\n",
      "        MaxPool2d-10          [-1, 256, 35, 51]               0\n",
      "        Dropout2d-11          [-1, 256, 35, 51]               0\n",
      "           Conv2d-12          [-1, 384, 35, 51]         885,120\n",
      "             SELU-13          [-1, 384, 35, 51]               0\n",
      "           Conv2d-14          [-1, 256, 35, 51]         884,992\n",
      "             SELU-15          [-1, 256, 35, 51]               0\n",
      "        MaxPool2d-16          [-1, 256, 17, 25]               0\n",
      "           Conv2d-17          [-1, 256, 17, 25]         590,080\n",
      "             SELU-18          [-1, 256, 17, 25]               0\n",
      "        MaxPool2d-19           [-1, 256, 8, 12]               0\n",
      "        Dropout2d-20           [-1, 256, 8, 12]               0\n",
      "          Flatten-21                [-1, 24576]               0\n",
      "           Linear-22                 [-1, 1024]      25,166,848\n",
      "             SELU-23                 [-1, 1024]               0\n",
      "        Dropout1d-24                 [-1, 1024]               0\n",
      "           Linear-25                  [-1, 128]         131,200\n",
      "           Conv2d-26         [-1, 96, 145, 210]          11,712\n",
      "             SELU-27         [-1, 96, 145, 210]               0\n",
      "      BatchNorm2d-28         [-1, 96, 145, 210]             192\n",
      "             SELU-29         [-1, 96, 145, 210]               0\n",
      "        MaxPool2d-30          [-1, 96, 72, 104]               0\n",
      "           Conv2d-31         [-1, 256, 72, 104]         614,656\n",
      "             SELU-32         [-1, 256, 72, 104]               0\n",
      "      BatchNorm2d-33         [-1, 256, 72, 104]             512\n",
      "             SELU-34         [-1, 256, 72, 104]               0\n",
      "        MaxPool2d-35          [-1, 256, 35, 51]               0\n",
      "        Dropout2d-36          [-1, 256, 35, 51]               0\n",
      "           Conv2d-37          [-1, 384, 35, 51]         885,120\n",
      "             SELU-38          [-1, 384, 35, 51]               0\n",
      "           Conv2d-39          [-1, 256, 35, 51]         884,992\n",
      "             SELU-40          [-1, 256, 35, 51]               0\n",
      "        MaxPool2d-41          [-1, 256, 17, 25]               0\n",
      "           Conv2d-42          [-1, 256, 17, 25]         590,080\n",
      "             SELU-43          [-1, 256, 17, 25]               0\n",
      "        MaxPool2d-44           [-1, 256, 8, 12]               0\n",
      "        Dropout2d-45           [-1, 256, 8, 12]               0\n",
      "          Flatten-46                [-1, 24576]               0\n",
      "           Linear-47                 [-1, 1024]      25,166,848\n",
      "             SELU-48                 [-1, 1024]               0\n",
      "        Dropout1d-49                 [-1, 1024]               0\n",
      "           Linear-50                  [-1, 128]         131,200\n",
      "================================================================\n",
      "Total params: 56,570,624\n",
      "Trainable params: 56,570,624\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4435.77\n",
      "Forward/backward pass size (MB): 361.35\n",
      "Params size (MB): 215.80\n",
      "Estimated Total Size (MB): 5012.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Model_BN()\n",
    "model.to('cuda')\n",
    "input_size = [(1, 155, 220), (1, 155, 220)]  # Define input sizes as a list of tuples\n",
    "summary(model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_model_custom = Model_BN()\n",
    "\n",
    "optimizer_bn = torch.optim.RMSprop(params=bn_model_custom.parameters(), lr=1e-4, weight_decay=0.0005, momentum=0.9, eps=1e-8)\n",
    "\n",
    "scheduler_bn = torch.optim.lr_scheduler.StepLR(optimizer=optimizer_bn, step_size=10, gamma=0.1)\n",
    "\n",
    "train_data = SiameseDataset('../Data/custom/used data/train.csv', '../Data/custom/full', transforms=transform)\n",
    "val_data = SiameseDataset('../Data/custom/used data/val.csv', '../Data/custom/full', transforms=transform)\n",
    "\n",
    "TrainDataloader = DataLoader(train_data, batch_size=32)\n",
    "ValDataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "TrainLoop(bn_model_custom, optimizer_bn, ContrastiveLoss(), 20, scheduler_bn, TrainDataloader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TrainDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 145, 210]          11,712\n",
      "              SELU-2         [-1, 96, 145, 210]               0\n",
      "       BatchNorm2d-3         [-1, 96, 145, 210]             192\n",
      "              SELU-4         [-1, 96, 145, 210]               0\n",
      "         MaxPool2d-5          [-1, 96, 72, 104]               0\n",
      "            Conv2d-6         [-1, 256, 72, 104]         614,656\n",
      "              SELU-7         [-1, 256, 72, 104]               0\n",
      "       BatchNorm2d-8         [-1, 256, 72, 104]             512\n",
      "              SELU-9         [-1, 256, 72, 104]               0\n",
      "        MaxPool2d-10          [-1, 256, 35, 51]               0\n",
      "        Dropout2d-11          [-1, 256, 35, 51]               0\n",
      "           Conv2d-12          [-1, 384, 35, 51]         885,120\n",
      "             SELU-13          [-1, 384, 35, 51]               0\n",
      "           Conv2d-14          [-1, 256, 35, 51]         884,992\n",
      "             SELU-15          [-1, 256, 35, 51]               0\n",
      "        MaxPool2d-16          [-1, 256, 17, 25]               0\n",
      "           Conv2d-17          [-1, 256, 17, 25]         590,080\n",
      "             SELU-18          [-1, 256, 17, 25]               0\n",
      "        MaxPool2d-19           [-1, 256, 8, 12]               0\n",
      "        Dropout2d-20           [-1, 256, 8, 12]               0\n",
      "          Flatten-21                [-1, 24576]               0\n",
      "           Linear-22                 [-1, 1024]      25,166,848\n",
      "             SELU-23                 [-1, 1024]               0\n",
      "        Dropout1d-24                 [-1, 1024]               0\n",
      "           Linear-25                  [-1, 128]         131,200\n",
      "================================================================\n",
      "Total params: 28,285,312\n",
      "Trainable params: 28,285,312\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 180.67\n",
      "Params size (MB): 107.90\n",
      "Estimated Total Size (MB): 288.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "class Model_BN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Siamese CNN model with Batch Normalization.\n",
    "\n",
    "    This model consists of three shared convolutional layers with Batch Normalization\n",
    "    followed by Fully Connected layers for feature extraction. The architecture is designed\n",
    "    to take two input images (x_genuine and x_test) and process them through the same\n",
    "    set of convolutional layers before extracting feature vectors.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Shape:\n",
    "        - Input:\n",
    "            - x_genuine (torch.Tensor): A 4D tensor representing a batch of genuine images\n",
    "              with shape (batch_size, channels, height, width).\n",
    "            - x_test (torch.Tensor): A 4D tensor representing a batch of test images\n",
    "              with shape (batch_size, channels, height, width).\n",
    "\n",
    "        - Output:\n",
    "            - y_genuine (torch.Tensor): A 2D tensor representing the feature vectors of the\n",
    "              genuine images with shape (batch_size, 128).\n",
    "            - y_test (torch.Tensor): A 2D tensor representing the feature vectors of the\n",
    "              test images with shape (batch_size, 128).\n",
    "\n",
    "    Model Architecture:\n",
    "        --------------------------------------------------------------------\n",
    "        Layer (type)            Output Shape                        Param #\n",
    "        ====================================================================\n",
    "        Conv2d-1                [batch_size, 96, 210, 145]          34,944\n",
    "        SELU-2                  [batch_size, 96, 210, 145]               0\n",
    "        BatchNorm2d-3           [batch_size, 96, 210, 145]             192\n",
    "        SELU-4                  [batch_size, 96, 210, 145]               0\n",
    "        MaxPool2d-5             [batch_size, 96, 104, 72]                0\n",
    "        Conv2d-6                [batch_size, 256, 104, 72]         614,656\n",
    "        SELU-7                  [batch_size, 256, 104, 72]               0\n",
    "        BatchNorm2d-8           [batch_size, 256, 104, 72]             512\n",
    "        SELU-9                  [batch_size, 256, 104, 72]               0\n",
    "        MaxPool2d-10            [batch_size, 256, 51, 35]                0\n",
    "        Dropout2d-11            [batch_size, 256, 51, 35]                0\n",
    "        Conv2d-12               [batch_size, 384, 51, 35]          885,120\n",
    "        SELU-13                 [batch_size, 384, 51, 35]                0\n",
    "        Conv2d-14               [batch_size, 256, 51, 35]          884,992\n",
    "        SELU-15                 [batch_size, 256, 51, 35]                0\n",
    "        MaxPool2d-16            [batch_size, 256, 25, 17]                0\n",
    "        Dropout2d-17            [batch_size, 256, 25, 17]                0\n",
    "        Flatten-18              [batch_size, 108800]                     0\n",
    "        Linear-19               [batch_size, 1024]             111,412,224\n",
    "        SELU-20                 [batch_size, 1024]                       0\n",
    "        Dropout1d-21            [batch_size, 1024]                       0\n",
    "        Linear-22               [batch_size, 128]                  131,200\n",
    "        ===================================================================\n",
    "        Total params: 113,963,840\n",
    "        Trainable params: 113,963,840\n",
    "        Non-trainable params: 0\n",
    "        -------------------------------------------------------------------\n",
    "\n",
    "    Note:\n",
    "        SELU activation is used after each convolutional layer, and Dropout is applied\n",
    "        for regularization to prevent overfitting.\n",
    "\n",
    "    Example:\n",
    "        # Create an instance of the Model_BN\n",
    "        model = Model_BN()\n",
    "\n",
    "        # Assuming you have loaded the genuine and test images as tensors\n",
    "        genuine_images = ...  # Tensor of genuine images\n",
    "        test_images = ...  # Tensor of test images\n",
    "\n",
    "        # Pass the images through the model\n",
    "        feature_vectors_genuine, feature_vectors_test = model(genuine_images, test_images)\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model_branch = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.BatchNorm2d(num_features=96),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.BatchNorm2d(num_features=256),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Dropout2d(p=0.3),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            torch.nn.Dropout2d(p=0.3),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=24576, out_features=1024),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Dropout1d(p=0.5),\n",
    "            torch.nn.Linear(in_features=1024, out_features=128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_genuine):\n",
    "        \"\"\"\n",
    "        Forward pass of the Siamese CNN model.\n",
    "\n",
    "        Args:\n",
    "            x_genuine (torch.Tensor): A batch of genuine images with shape (batch_size, channels, height, width).\n",
    "            x_test (torch.Tensor): A batch of test images with shape (batch_size, channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor representing the feature vectors of the genuine images with shape (batch_size, 128).\n",
    "            torch.Tensor: A tensor representing the feature vectors of the test images with shape (batch_size, 128).\n",
    "        \"\"\"\n",
    "        y_genuine = self.model_branch(x_genuine)\n",
    "        return y_genuine\n",
    "    \n",
    "model = Model_BN()\n",
    "model.to('cuda')\n",
    "input_size = [(1, 155, 220), (1, 155, 220)]  # Define input sizes as a list of tuples\n",
    "summary(model, (1, 155, 220))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
